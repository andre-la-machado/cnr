{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this Notebook, a LSTM Model will be tried for the Competitition Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set_style('darkgrid')\n",
    "from cnr_methods import get_selected_features, transform_data, revert_data,metric_cnr, get_simplified_data\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the data used correspond to the results of the Feature Engineering and Selection Step. For simplicity, during Hyperparameter Optimization, only Wind Farm 3 Training Data is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_selected_features(0)\n",
    "\n",
    "#full_data = full_data.rename({'Unnamed: 0' : 'Time'},axis=1)\n",
    "full_data = full_data.set_index('Time')\n",
    "\n",
    "full_label = pd.read_csv('Data/Y_train.csv')\n",
    "X = full_data[full_data['Set']=='Train']\n",
    "\n",
    "WF = 'WF3'\n",
    "X = X[X['WF']==WF]\n",
    "y = full_label[full_label['ID'].isin(X['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['ID','WF','Set'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                       U_100m    V_100m     U_10m     V_10m        T  \\\nTime                                                                   \n2018-05-01 01:00:00  5.789500  3.820200  1.054669  1.317597  275.690   \n2018-05-01 02:00:00  6.003300  3.920600  0.876879  1.483483  275.770   \n2018-05-01 03:00:00  5.931829  0.907656  0.949640  1.419591  276.875   \n2018-05-01 04:00:00  5.205300  1.683800  1.027462  1.029786  275.650   \n2018-05-01 05:00:00  4.845900  0.702200  1.011645  0.785352  275.530   \n\n                          CLCT  Wind Direction 100m  Wind Direction 10m  \\\nTime                                                                      \n2018-05-01 01:00:00  86.504507             0.583268            0.895782   \n2018-05-01 02:00:00  98.976088             0.578533            1.036951   \n2018-05-01 03:00:00  64.193607             0.151837            0.981212   \n2018-05-01 04:00:00  57.482484             0.312855            0.786528   \n2018-05-01 05:00:00  89.971463             0.143904            0.660129   \n\n                     Wind Speed 100m  V_100m_lag_21_days  ...  \\\nTime                                                      ...   \n2018-05-01 01:00:00         6.936299                 NaN  ...   \n2018-05-01 02:00:00         7.170127                 NaN  ...   \n2018-05-01 03:00:00         6.000870                 NaN  ...   \n2018-05-01 04:00:00         5.470862                 NaN  ...   \n2018-05-01 05:00:00         4.896512                 NaN  ...   \n\n                     V_10m_Rolling_14_Window_Variance  \\\nTime                                                    \n2018-05-01 01:00:00                               NaN   \n2018-05-01 02:00:00                               NaN   \n2018-05-01 03:00:00                               NaN   \n2018-05-01 04:00:00                               NaN   \n2018-05-01 05:00:00                               NaN   \n\n                     U_100m_Rolling_14_Window_Mean  Wind Speed 10m  \\\nTime                                                                 \n2018-05-01 01:00:00                            NaN        1.687717   \n2018-05-01 02:00:00                            NaN        1.723264   \n2018-05-01 03:00:00                            NaN        1.707938   \n2018-05-01 04:00:00                            NaN        1.454695   \n2018-05-01 05:00:00                            NaN        1.280704   \n\n                     V_100m_Rolling_7_Window_Mean  T_lag_21_days  \\\nTime                                                               \n2018-05-01 01:00:00                           NaN            NaN   \n2018-05-01 02:00:00                           NaN            NaN   \n2018-05-01 03:00:00                           NaN            NaN   \n2018-05-01 04:00:00                           NaN            NaN   \n2018-05-01 05:00:00                           NaN            NaN   \n\n                     U_10m_Rolling_14_Window_Variance  \\\nTime                                                    \n2018-05-01 01:00:00                               NaN   \n2018-05-01 02:00:00                               NaN   \n2018-05-01 03:00:00                               NaN   \n2018-05-01 04:00:00                               NaN   \n2018-05-01 05:00:00                               NaN   \n\n                     CLCT_Rolling_7_Window_Mean  V_100m_lag_7_days  \\\nTime                                                                 \n2018-05-01 01:00:00                         NaN                NaN   \n2018-05-01 02:00:00                         NaN                NaN   \n2018-05-01 03:00:00                         NaN                NaN   \n2018-05-01 04:00:00                         NaN                NaN   \n2018-05-01 05:00:00                         NaN                NaN   \n\n                     U_10m_lag_7_days  U_100m_lag_21_days  \nTime                                                       \n2018-05-01 01:00:00               NaN                 NaN  \n2018-05-01 02:00:00               NaN                 NaN  \n2018-05-01 03:00:00               NaN                 NaN  \n2018-05-01 04:00:00               NaN                 NaN  \n2018-05-01 05:00:00               NaN                 NaN  \n\n[5 rows x 93 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>U_100m</th>\n      <th>V_100m</th>\n      <th>U_10m</th>\n      <th>V_10m</th>\n      <th>T</th>\n      <th>CLCT</th>\n      <th>Wind Direction 100m</th>\n      <th>Wind Direction 10m</th>\n      <th>Wind Speed 100m</th>\n      <th>V_100m_lag_21_days</th>\n      <th>...</th>\n      <th>V_10m_Rolling_14_Window_Variance</th>\n      <th>U_100m_Rolling_14_Window_Mean</th>\n      <th>Wind Speed 10m</th>\n      <th>V_100m_Rolling_7_Window_Mean</th>\n      <th>T_lag_21_days</th>\n      <th>U_10m_Rolling_14_Window_Variance</th>\n      <th>CLCT_Rolling_7_Window_Mean</th>\n      <th>V_100m_lag_7_days</th>\n      <th>U_10m_lag_7_days</th>\n      <th>U_100m_lag_21_days</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 01:00:00</th>\n      <td>5.789500</td>\n      <td>3.820200</td>\n      <td>1.054669</td>\n      <td>1.317597</td>\n      <td>275.690</td>\n      <td>86.504507</td>\n      <td>0.583268</td>\n      <td>0.895782</td>\n      <td>6.936299</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.687717</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>6.003300</td>\n      <td>3.920600</td>\n      <td>0.876879</td>\n      <td>1.483483</td>\n      <td>275.770</td>\n      <td>98.976088</td>\n      <td>0.578533</td>\n      <td>1.036951</td>\n      <td>7.170127</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.723264</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>5.931829</td>\n      <td>0.907656</td>\n      <td>0.949640</td>\n      <td>1.419591</td>\n      <td>276.875</td>\n      <td>64.193607</td>\n      <td>0.151837</td>\n      <td>0.981212</td>\n      <td>6.000870</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.707938</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>5.205300</td>\n      <td>1.683800</td>\n      <td>1.027462</td>\n      <td>1.029786</td>\n      <td>275.650</td>\n      <td>57.482484</td>\n      <td>0.312855</td>\n      <td>0.786528</td>\n      <td>5.470862</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.454695</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>4.845900</td>\n      <td>0.702200</td>\n      <td>1.011645</td>\n      <td>0.785352</td>\n      <td>275.530</td>\n      <td>89.971463</td>\n      <td>0.143904</td>\n      <td>0.660129</td>\n      <td>4.896512</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.280704</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 93 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Creation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Model(input_shape):\n",
    "  # Numerical branch\n",
    "\n",
    "  input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "  hidden_1 = tf.keras.layers.LSTM(units=256, activation=\"relu\", kernel_initializer=\"he_normal\")(input_layer)\n",
    "  hidden_1 = tf.keras.layers.Dropout(rate=0.5)(hidden_1)\n",
    "  hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
    "\n",
    "  # Output\n",
    "\n",
    "  outputs = tf.keras.layers.PReLU()(hidden_1)\n",
    "  outputs = tf.keras.layers.Dropout(rate=0.5)(outputs)\n",
    "  outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
    "  outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(outputs)\n",
    "\n",
    "  model = tf.keras.Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Model((X.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 93, 1)]           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 256)               264192    \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 256)               1024      \n_________________________________________________________________\np_re_lu (PReLU)              (None, 256)               256       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense (Dense)                (None, 1)                 257       \n=================================================================\nTotal params: 266,753\nTrainable params: 265,729\nNon-trainable params: 1,024\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_cnr(preds,labels):\n",
    "    cape_cnr = 100*np.sum(np.abs(preds-labels))/np.sum(labels)\n",
    "    return 'CAPE', cape_cnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(317)\n",
    "tf.random.set_seed(317)\n",
    "\n",
    "patience = 10\n",
    "epochs = 40\n",
    "k_fold_splits = 5\n",
    "total_it = 120\n",
    "monitor = tf.keras.metrics.RootMeanSquaredError()\n",
    "batch_size = 1 * ((len(X) - len(X) // k_fold_splits) // (total_it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ". Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 170ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 23/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 24/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 168ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 25/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 26/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 176ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 27/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 169ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 28/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 173ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 29/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 30/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 169ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 31/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 32/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 167ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 33/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 172ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 34/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 172ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 35/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 168ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 36/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 37/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 38/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 168ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 39/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 172ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 40/40\n58/58 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n58/58 [==============================] - 10s 169ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 1/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 160ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 2/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 3/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 4/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 5/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 156ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 6/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 161ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 7/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 162ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 8/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 9/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 10/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 156ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 11/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 12/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 13/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 14/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 155ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 15/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 16/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 158ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 17/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 18/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 160ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 19/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 13s 171ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 20/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 157ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 21/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 22/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 14s 184ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 23/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 14s 185ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 24/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 159ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 25/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 12s 161ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 26/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 14s 182ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 27/40\n77/77 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nanWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,root_mean_squared_error,val_loss,val_root_mean_squared_error\n77/77 [==============================] - 13s 165ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\nEpoch 28/40\n41/77 [==============>...............] - ETA: 5s - loss: nan - root_mean_squared_error: nan"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-41aeeca41d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Train the Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hinge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRootMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Train and Validation Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define Time Split Cross Validation\n",
    "tscv = TimeSeriesSplit(n_splits=k_fold_splits)\n",
    "\n",
    "# Separating Data from Hold Out Set\n",
    "\n",
    "X_cv, _, y_cv, _ = train_test_split(X, y, test_size=0.125, shuffle=False)\n",
    "\n",
    "train_scores = np.empty(0)\n",
    "val_scores = np.empty(0)\n",
    "test_scores = np.empty(0)\n",
    "for train_index, test_index in tscv.split(X_cv):\n",
    "\n",
    "    # Get the Data of the Split\n",
    "    X_train, X_test = X_cv.iloc[train_index], X_cv.iloc[test_index]\n",
    "    y_train, y_test = y_cv.iloc[train_index], y_cv.iloc[test_index]\n",
    "\n",
    "    # Separating Training Set of Split on Train and Validation Subsets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.143, shuffle=False)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks_list = [tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience, verbose=0, min_delta=1e-8)]\n",
    "\n",
    "    # Train the Model\n",
    "    model.compile(optimizer='adam', loss='hinge', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    history = model.fit(x = X_train, y = y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, y_val), callbacks=callbacks_list)\n",
    "\n",
    "    # Train and Validation Score\n",
    "    #train_score = np.array(progress['train']['CAPE']).mean()\n",
    "    #val_score = np.array(progress['eval']['CAPE']).mean()\n",
    "\n",
    "    # Test Score\n",
    "    preds = model.predict(X_test,batch_size = batch_size,callbacks=callbacks_list)\n",
    "    test_score = metric_cnr(preds,y_test)\n",
    "\n",
    "    #train_scores = np.append(train_scores,train_score)\n",
    "    #val_scores = np.append(val_scores,val_score)\n",
    "    test_scores = np.append(test_scores,test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n 'accuracy': [0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607,\n  0.020389843732118607],\n 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n 'val_accuracy': [0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897,\n  0.016129031777381897]}"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "history.history[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold Out Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.125, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.143, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594771319241",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}