{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Feature Engineering process, defined on Part 1, is applied to all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tsfresh\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from cnr_methods import get_simplified_data, transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, all the process created on Part 1 is organized on Functions before applying to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_features(n_features):\n",
    "    selected_features = pd.read_csv(r'Feature Selection\\Importance_WF1.csv')\n",
    "    selected_features = selected_features[:n_features]['feature']\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_features(feature_data):\n",
    "\n",
    "    index = feature_data.index\n",
    "    features = ['T', 'CLCT', 'U_100m','V_100m','U_10m','V_10m']\n",
    "\n",
    "    # Wind Speed Vector\n",
    "    feature_data['Wind Speed 100m'] = np.sqrt(feature_data['U_100m']**2 + feature_data['V_100m']**2)\n",
    "    feature_data['Wind Direction 100m'] = np.arctan(feature_data['V_100m']/feature_data['U_100m'])\n",
    "    feature_data['Wind Speed 10m'] = np.sqrt(feature_data['U_10m']**2 + feature_data['V_10m']**2)\n",
    "    feature_data['Wind Direction 10m'] = np.arctan(feature_data['V_10m']/feature_data['U_10m'])\n",
    "\n",
    "    feature_data['Wind Direction 100m'] = feature_data['Wind Direction 100m'].apply(lambda x: 360 + x if x < 0 else x)\n",
    "    feature_data['Wind Direction 10m'] = feature_data['Wind Direction 10m'].apply(lambda x: 360 + x if x < 0 else x)\n",
    "\n",
    "    # Time Relative Variables \n",
    "\n",
    "    for column in features:\n",
    "        feature_data[column + '_lag_7_days'] = feature_data[column].shift(7)\n",
    "        feature_data[column + '_lag_14_days'] = feature_data[column].shift(14)\n",
    "        feature_data[column + '_lag_21_days'] = feature_data[column].shift(21)\n",
    "\n",
    "    feature_data['Month_Number'] = feature_data.index.month # Month Number\n",
    "\n",
    "    mean_month = feature_data.groupby('Month_Number').mean()[features]\n",
    "    variance_month = feature_data.groupby('Month_Number').var()[features]\n",
    "\n",
    "    mean_month.columns = mean_month.columns + '_Last_Month_Mean'\n",
    "    variance_month.columns = variance_month.columns + 'Last_Month_Variance'\n",
    "\n",
    "    month_data = mean_month.merge(variance_month,on='Month_Number',how='left')\n",
    "    month_data = month_data.reset_index()\n",
    "    month_data['Month_Number'] = month_data['Month_Number'] + 1\n",
    "    month_data['Month_Number'] = month_data['Month_Number'].replace({13:1})\n",
    "\n",
    "    feature_data = feature_data.merge(month_data,on='Month_Number',how='left')\n",
    "    feature_data.index = index\n",
    "\n",
    "    # Periodical Features\n",
    "\n",
    "    day = feature_data.index.day\n",
    "    hour = feature_data.index.hour\n",
    "    minute = feature_data.index.minute\n",
    "    dayofweek = feature_data.index.dayofweek\n",
    "    dayofyear = feature_data.index.dayofyear\n",
    "    days_in_month = feature_data.index.days_in_month\n",
    "\n",
    "    feature_data[\"cos_day\"], feature_data[\"sin_day\"] = (\n",
    "    np.cos(2 * np.pi * (day - 1) / days_in_month),\n",
    "    np.sin(2 * np.pi * (day - 1) / days_in_month),\n",
    "    )\n",
    "\n",
    "    feature_data[\"cos_hour\"], feature_data[\"sin_hour\"] = (\n",
    "        np.cos(2 * np.pi * hour / 24),\n",
    "        np.sin(2 * np.pi * hour / 24),\n",
    "        )\n",
    "\n",
    "    feature_data[\"cos_minute\"], feature_data[\"sin_minute\"] = (\n",
    "        np.cos(2 * np.pi * minute / 60),\n",
    "        np.sin(2 * np.pi * minute / 60),\n",
    "    )\n",
    "\n",
    "    feature_data[\"cos_dayofyear\"], feature_data[\"sin_dayofyear\"] = (\n",
    "        np.cos(2 * np.pi * (dayofyear - 1) / 365),\n",
    "        np.sin(2 * np.pi * (dayofyear - 1) / 365),\n",
    "    )\n",
    "\n",
    "    feature_data[\"cos_dayofweek\"], feature_data[\"sin_dayofweek\"] = (\n",
    "        np.cos(2 * np.pi * dayofweek / 7),\n",
    "        np.sin(2 * np.pi * dayofweek / 7),\n",
    "    )\n",
    "\n",
    "    # Distance from Max and Min\n",
    "\n",
    "    for column in features:\n",
    "        feature_data[column + '_Distance_Max'] = feature_data.index - feature_data[column].idxmax()\n",
    "        feature_data[column + '_Distance_Min'] = feature_data.index - feature_data[column].idxmin()\n",
    "        feature_data[column + '_Distance_Max'] = feature_data[column + '_Distance_Max'].apply(lambda x : x.days)\n",
    "        feature_data[column + '_Distance_Min'] = feature_data[column + '_Distance_Min'].apply(lambda x : x.days)\n",
    "\n",
    "    # Rolling Window Statistics\n",
    "\n",
    "    for column in features:\n",
    "        feature_data[column + '_Rolling_7_Window_Mean'] = feature_data[column].rolling(window=7).mean()\n",
    "        feature_data[column + '_Rolling_14_Window_Mean'] = feature_data[column].rolling(window=14).mean()\n",
    "        feature_data[column + '_Rolling_7_Window_Variance'] = feature_data[column].rolling(window=7).var()\n",
    "        feature_data[column + '_Rolling_14_Window_Variance'] = feature_data[column].rolling(window=14).var()\n",
    "\n",
    "    # Expanded Window Statistics\n",
    "\n",
    "    for column in features:\n",
    "        feature_data[column + '_Expanded_Window_Min'] = feature_data[column].expanding().min()\n",
    "        feature_data[column + '_Expanded_Window_Min'] = feature_data[column].expanding().max()\n",
    "\n",
    "\n",
    "    # Dropping Base Features \n",
    "    #features.append(['Month_Number','Quarter Number'])\n",
    "    feature_data = feature_data.drop(features,axis=1)\n",
    "\n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_data(X): \n",
    "    feature_data = pd.DataFrame()\n",
    "    for WF in X['WF'].unique():\n",
    "        X_WF = X[X['WF']==WF]\n",
    "\n",
    "        X_WF = get_manual_features(X_WF)\n",
    "\n",
    "        X_WF['WF'] = WF\n",
    "        feature_data = pd.concat([feature_data,X_WF],axis=0)\n",
    "\n",
    "    feature_data = pd.concat([X,feature_data],axis=1) \n",
    "\n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Feature Engineering is properly applied on the Full Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y_train = get_simplified_data()\n",
    "\n",
    "X_train = X[X['Set']=='Train']\n",
    "X_test = X[X['Set']=='Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_features_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_features_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Set'] = 'Train'\n",
    "X_test['Set'] = 'Test'\n",
    "\n",
    "feature_data = pd.concat([X_train,X_test],axis=0)\n",
    "\n",
    "feature_data = feature_data.loc[:,~feature_data.columns.duplicated()]\n",
    "\n",
    "\n",
    "feature_data.to_csv(r'C:\\Users\\andre_\\OneDrive\\Documentos\\Feature Selection\\Selected_Features_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}