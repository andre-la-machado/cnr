{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cnr_methods import get_simplified_data, transform_data, LOFO_GPU_Importance\n",
    "\n",
    "# Feature Engineering Library for Time Series\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this pipeline, only Training Set will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_simplified_data()\n",
    "full_data = full_data[full_data['Set']=='Train']\n",
    "y_train = pd.read_csv('Data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the other Notebooks, we will transform the Column 'Time' to Datetime format and set as the index of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Time'] = pd.to_datetime(full_data['Time'],dayfirst=True)\n",
    "full_data = full_data.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     ID   WF    U_100m    V_100m     U_10m     V_10m       T  \\\nTime                                                                           \n2018-05-01 01:00:00   1  WF1 -2.248500 -3.257800  1.254603 -0.289687  286.44   \n2018-05-01 02:00:00   2  WF1 -2.434500 -1.446100  2.490908 -0.413370  286.26   \n2018-05-01 03:00:00   3  WF1 -1.707402 -0.853745  0.997093 -1.415138  287.00   \n2018-05-01 04:00:00   4  WF1  3.706500 -6.217400  0.689598 -0.961441  284.78   \n2018-05-01 05:00:00   5  WF1  3.813400 -5.444600  0.290994 -0.294963  284.46   \n\n                          CLCT    Set  \nTime                                   \n2018-05-01 01:00:00  82.543144  Train  \n2018-05-01 02:00:00  99.990844  Train  \n2018-05-01 03:00:00  98.367235  Train  \n2018-05-01 04:00:00  94.860604  Train  \n2018-05-01 05:00:00  95.905879  Train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>WF</th>\n      <th>U_100m</th>\n      <th>V_100m</th>\n      <th>U_10m</th>\n      <th>V_10m</th>\n      <th>T</th>\n      <th>CLCT</th>\n      <th>Set</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 01:00:00</th>\n      <td>1</td>\n      <td>WF1</td>\n      <td>-2.248500</td>\n      <td>-3.257800</td>\n      <td>1.254603</td>\n      <td>-0.289687</td>\n      <td>286.44</td>\n      <td>82.543144</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>2</td>\n      <td>WF1</td>\n      <td>-2.434500</td>\n      <td>-1.446100</td>\n      <td>2.490908</td>\n      <td>-0.413370</td>\n      <td>286.26</td>\n      <td>99.990844</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>3</td>\n      <td>WF1</td>\n      <td>-1.707402</td>\n      <td>-0.853745</td>\n      <td>0.997093</td>\n      <td>-1.415138</td>\n      <td>287.00</td>\n      <td>98.367235</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>4</td>\n      <td>WF1</td>\n      <td>3.706500</td>\n      <td>-6.217400</td>\n      <td>0.689598</td>\n      <td>-0.961441</td>\n      <td>284.78</td>\n      <td>94.860604</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>5</td>\n      <td>WF1</td>\n      <td>3.813400</td>\n      <td>-5.444600</td>\n      <td>0.290994</td>\n      <td>-0.294963</td>\n      <td>284.46</td>\n      <td>95.905879</td>\n      <td>Train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the work, we will generate features for just one Wind Farm. When doing modelling, the features, as the models, will be generated for all Wind Farms separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF = 'WF1'\n",
    "data = full_data[full_data['WF']==WF]\n",
    "y_train = y_train[y_train['ID'].isin(data['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        ID   WF    U_100m    V_100m     U_10m     V_10m  \\\nTime                                                                      \n2018-05-01 01:00:00      1  WF1 -2.248500 -3.257800  1.254603 -0.289687   \n2018-05-01 02:00:00      2  WF1 -2.434500 -1.446100  2.490908 -0.413370   \n2018-05-01 03:00:00      3  WF1 -1.707402 -0.853745  0.997093 -1.415138   \n2018-05-01 04:00:00      4  WF1  3.706500 -6.217400  0.689598 -0.961441   \n2018-05-01 05:00:00      5  WF1  3.813400 -5.444600  0.290994 -0.294963   \n...                    ...  ...       ...       ...       ...       ...   \n2019-01-15 20:00:00  37371  WF6 -0.995550 -5.465200  0.645083 -0.911460   \n2019-01-15 21:00:00  37372  WF6 -0.221900 -4.461200  0.430113 -0.701325   \n2019-01-15 22:00:00  37373  WF6 -0.874850 -4.515750  0.123965 -0.696413   \n2019-01-15 23:00:00  37374  WF6 -0.922000 -3.989200 -0.065344 -0.542009   \n2019-01-16 00:00:00  37375  WF6 -0.569800 -1.990900 -0.102728 -0.389288   \n\n                              T       CLCT    Set  \nTime                                               \n2018-05-01 01:00:00  286.440000  82.543144  Train  \n2018-05-01 02:00:00  286.260000  99.990844  Train  \n2018-05-01 03:00:00  287.000000  98.367235  Train  \n2018-05-01 04:00:00  284.780000  94.860604  Train  \n2018-05-01 05:00:00  284.460000  95.905879  Train  \n...                         ...        ...    ...  \n2019-01-15 20:00:00  273.935000   0.000000  Train  \n2019-01-15 21:00:00  275.073746   0.000000  Train  \n2019-01-15 22:00:00  272.945000   0.000000  Train  \n2019-01-15 23:00:00  272.530000   0.000000  Train  \n2019-01-16 00:00:00  274.049392   0.000000  Train  \n\n[37375 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>WF</th>\n      <th>U_100m</th>\n      <th>V_100m</th>\n      <th>U_10m</th>\n      <th>V_10m</th>\n      <th>T</th>\n      <th>CLCT</th>\n      <th>Set</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 01:00:00</th>\n      <td>1</td>\n      <td>WF1</td>\n      <td>-2.248500</td>\n      <td>-3.257800</td>\n      <td>1.254603</td>\n      <td>-0.289687</td>\n      <td>286.440000</td>\n      <td>82.543144</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>2</td>\n      <td>WF1</td>\n      <td>-2.434500</td>\n      <td>-1.446100</td>\n      <td>2.490908</td>\n      <td>-0.413370</td>\n      <td>286.260000</td>\n      <td>99.990844</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>3</td>\n      <td>WF1</td>\n      <td>-1.707402</td>\n      <td>-0.853745</td>\n      <td>0.997093</td>\n      <td>-1.415138</td>\n      <td>287.000000</td>\n      <td>98.367235</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>4</td>\n      <td>WF1</td>\n      <td>3.706500</td>\n      <td>-6.217400</td>\n      <td>0.689598</td>\n      <td>-0.961441</td>\n      <td>284.780000</td>\n      <td>94.860604</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>5</td>\n      <td>WF1</td>\n      <td>3.813400</td>\n      <td>-5.444600</td>\n      <td>0.290994</td>\n      <td>-0.294963</td>\n      <td>284.460000</td>\n      <td>95.905879</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 20:00:00</th>\n      <td>37371</td>\n      <td>WF6</td>\n      <td>-0.995550</td>\n      <td>-5.465200</td>\n      <td>0.645083</td>\n      <td>-0.911460</td>\n      <td>273.935000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 21:00:00</th>\n      <td>37372</td>\n      <td>WF6</td>\n      <td>-0.221900</td>\n      <td>-4.461200</td>\n      <td>0.430113</td>\n      <td>-0.701325</td>\n      <td>275.073746</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 22:00:00</th>\n      <td>37373</td>\n      <td>WF6</td>\n      <td>-0.874850</td>\n      <td>-4.515750</td>\n      <td>0.123965</td>\n      <td>-0.696413</td>\n      <td>272.945000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 23:00:00</th>\n      <td>37374</td>\n      <td>WF6</td>\n      <td>-0.922000</td>\n      <td>-3.989200</td>\n      <td>-0.065344</td>\n      <td>-0.542009</td>\n      <td>272.530000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-16 00:00:00</th>\n      <td>37375</td>\n      <td>WF6</td>\n      <td>-0.569800</td>\n      <td>-1.990900</td>\n      <td>-0.102728</td>\n      <td>-0.389288</td>\n      <td>274.049392</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n  </tbody>\n</table>\n<p>37375 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, using the Zonal and Meridional Components of Wind, the Magnitude and Direction of Wind Vector for 100m and 10m height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]\n",
    "feature_data['Wind Speed 100m'] = np.sqrt(feature_data['U_100m']**2 + feature_data['V_100m']**2)\n",
    "feature_data['Wind Direction 100m'] = np.arctan(feature_data['V_100m']/feature_data['U_100m'])\n",
    "feature_data['Wind Speed 10m'] = np.sqrt(feature_data['U_10m']**2 + feature_data['V_10m']**2)\n",
    "feature_data['Wind Direction 10m'] = np.arctan(feature_data['V_10m']/feature_data['U_10m'])\n",
    "feature_data = feature_data.drop(['U_100m','V_100m','U_10m','V_10m'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Reference for Negative Angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data['Wind Direction 100m'] = feature_data['Wind Direction 100m'].apply(lambda x: 360 + x if x < 0 else x)\n",
    "feature_data['Wind Direction 10m'] = feature_data['Wind Direction 10m'].apply(lambda x: 360 + x if x < 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wind Speed and Direction instead of U and V, we will create some variables over the Numerical Variables from the simplified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['T', 'CLCT', 'Wind Speed 100m','Wind Direction 100m', 'Wind Speed 10m', 'Wind Direction 10m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Relative Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,  Values for Last Week and Month for each Numerical Feature are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_last_week'] = feature_data[column].shift(7)\n",
    "    feature_data[column + '_last_month'] = feature_data[column].shift(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Month and Quarter Statistics(Mean,Median,Variance) are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data['Month_Number'] = feature_data.index.month\n",
    "feature_data['Quarter_Number'] = feature_data.index.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "mean_month = feature_data.groupby('Month_Number').mean()[features]\n",
    "median_month = feature_data.groupby('Month_Number').median()[features]\n",
    "variance_month = feature_data.groupby('Month_Number').var()[features]\n",
    "\n",
    "# Quarter\n",
    "mean_quarter = feature_data.groupby('Quarter_Number').mean()[features]\n",
    "median_quarter = feature_data.groupby('Quarter_Number').median()[features]\n",
    "variance_quarter = feature_data.groupby('Quarter_Number').var()[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "mean_month.columns = mean_month.columns + '_Month_Mean'\n",
    "median_month.columns = median_month.columns + '_Month_Median'\n",
    "variance_month.columns = variance_month.columns + '_Month_Variance'\n",
    "\n",
    "# Quarter\n",
    "mean_quarter.columns = mean_quarter.columns + '_Quarter_Mean'\n",
    "median_quarter.columns = median_quarter.columns + '_Quarterh_Median'\n",
    "variance_quarter.columns = variance_quarter.columns + '_Quarter_Variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "feature_data = feature_data.merge(mean_month,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(median_month,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(variance_month,on='Month_Number',how='left')\n",
    "\n",
    "# Quarter\n",
    "feature_data = feature_data.merge(mean_quarter,on='Quarter_Number',how='left')\n",
    "feature_data = feature_data.merge(median_quarter,on='Quarter_Number',how='left')\n",
    "feature_data = feature_data.merge(variance_quarter,on='Quarter_Number',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.index = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For periodical Features, here represented by days (Of Month, Week and Year), hour and minutes, the features are applied to sinusoidal functions to replicate the cyclic nature of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = feature_data.index.day\n",
    "hour = feature_data.index.hour\n",
    "minute = feature_data.index.minute\n",
    "dayofweek = feature_data.index.dayofweek\n",
    "dayofyear = feature_data.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_in_month = feature_data.index.days_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data[\"cos_day\"], feature_data[\"sin_day\"] = (\n",
    "    np.cos(2 * np.pi * (day - 1) / days_in_month),\n",
    "    np.sin(2 * np.pi * (day - 1) / days_in_month),\n",
    "    )\n",
    "\n",
    "feature_data[\"cos_hour\"], feature_data[\"sin_hour\"] = (\n",
    "    np.cos(2 * np.pi * hour / 24),\n",
    "    np.sin(2 * np.pi * hour / 24),\n",
    "    )\n",
    "\n",
    "feature_data[\"cos_minute\"], feature_data[\"sin_minute\"] = (\n",
    "    np.cos(2 * np.pi * minute / 60),\n",
    "    np.sin(2 * np.pi * minute / 60),\n",
    ")\n",
    "\n",
    "feature_data[\"cos_dayofyear\"], feature_data[\"sin_dayofyear\"] = (\n",
    "    np.cos(2 * np.pi * (dayofyear - 1) / 365),\n",
    "    np.sin(2 * np.pi * (dayofyear - 1) / 365),\n",
    ")\n",
    "\n",
    "feature_data[\"cos_dayofweek\"], feature_data[\"sin_dayofweek\"] = (\n",
    "    np.cos(2 * np.pi * dayofweek / 7),\n",
    "    np.sin(2 * np.pi * dayofweek / 7),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance of Position of Max and Min (Already on Tsfresh, check it later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_Distance_Max'] = feature_data.index - feature_data[column].idxmax()\n",
    "    feature_data[column + '_Distance_Min'] = feature_data.index - feature_data[column].idxmin()\n",
    "    feature_data[column + '_Distance_Max'] = feature_data[column + '_Distance_Max'].apply(lambda x : x.days)\n",
    "    feature_data[column + '_Distance_Min'] = feature_data[column + '_Distance_Min'].apply(lambda x : x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Window Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transformations (Check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Tsfresh, a Python Library that automates Feature Engineering for Time Series Data. We generate new features for all the columns on the Simplified Data, as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Feature Extraction: 100%|██████████| 15/15 [02:16<00:00,  9.10s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:14<00:00,  8.99s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:13<00:00,  8.91s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:22<00:00,  9.50s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:08<00:00,  8.58s/it]\nFeature Extraction: 100%|██████████| 15/15 [01:41<00:00,  6.78s/it]\n"
    }
   ],
   "source": [
    "tsfresh_data = pd.DataFrame()\n",
    "for variable in ['U_100m','V_100m','U_10m','V_10m','T','CLCT']: \n",
    "    df_shift, y = make_forecasting_frame(data[variable],kind=variable,max_timeshift=20,rolling_direction=1)\n",
    "    X = extract_features(df_shift, column_id=\"id\", column_sort=\"time\", column_value=\"value\", impute_function=impute,show_warnings=False,n_jobs=3)\n",
    "    X['Feature'] = variable\n",
    "    tsfresh_data = tsfresh_data.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process tsfresh_data to pass column 'Features' to the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.pivot(columns='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data.columns = tsfresh_data.columns.map('{0[0]}|{0[1]}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     value__abs_energy|CLCT  value__abs_energy|T  \\\nid                                                                 \n2018-05-01 02:00:00             6813.370572           82047.8736   \n2018-05-01 03:00:00            16811.539518          163992.6612   \n2018-05-01 04:00:00            26487.652359          246361.6612   \n2018-05-01 05:00:00            35486.186521          327461.3096   \n2018-05-01 06:00:00            44684.124127          408378.8012   \n\n                     value__abs_energy|U_100m  value__abs_energy|U_10m  \\\nid                                                                       \n2018-05-01 02:00:00                  5.055752                 1.574030   \n2018-05-01 03:00:00                 10.982542                 7.778652   \n2018-05-01 04:00:00                 13.897765                 8.772845   \n2018-05-01 05:00:00                 27.635908                 9.248391   \n2018-05-01 06:00:00                 42.177927                 9.333069   \n\n                     value__abs_energy|V_100m  value__abs_energy|V_10m  \\\nid                                                                       \n2018-05-01 02:00:00                 10.613261                 0.083919   \n2018-05-01 03:00:00                 12.704466                 0.254793   \n2018-05-01 04:00:00                 13.433347                 2.257409   \n2018-05-01 05:00:00                 52.089410                 3.181777   \n2018-05-01 06:00:00                 81.733079                 3.268781   \n\n                     value__absolute_sum_of_changes|CLCT  \\\nid                                                         \n2018-05-01 02:00:00                             0.000000   \n2018-05-01 03:00:00                            17.447701   \n2018-05-01 04:00:00                            19.071310   \n2018-05-01 05:00:00                            22.577941   \n2018-05-01 06:00:00                            23.623216   \n\n                     value__absolute_sum_of_changes|T  \\\nid                                                      \n2018-05-01 02:00:00                              0.00   \n2018-05-01 03:00:00                              0.18   \n2018-05-01 04:00:00                              0.92   \n2018-05-01 05:00:00                              3.14   \n2018-05-01 06:00:00                              3.46   \n\n                     value__absolute_sum_of_changes|U_100m  \\\nid                                                           \n2018-05-01 02:00:00                               0.000000   \n2018-05-01 03:00:00                               0.186000   \n2018-05-01 04:00:00                               0.913098   \n2018-05-01 05:00:00                               6.327000   \n2018-05-01 06:00:00                               6.433900   \n\n                     value__absolute_sum_of_changes|U_10m  ...  \\\nid                                                         ...   \n2018-05-01 02:00:00                              0.000000  ...   \n2018-05-01 03:00:00                              1.236305  ...   \n2018-05-01 04:00:00                              2.730120  ...   \n2018-05-01 05:00:00                              3.037614  ...   \n2018-05-01 06:00:00                              3.436218  ...   \n\n                     value__variance|U_100m  value__variance|U_10m  \\\nid                                                                   \n2018-05-01 02:00:00                0.000000               0.000000   \n2018-05-01 03:00:00                0.008649               0.382112   \n2018-05-01 04:00:00                0.095117               0.425138   \n2018-05-01 05:00:00                6.458769               0.467797   \n2018-05-01 06:00:00                8.384555               0.556415   \n\n                     value__variance|V_100m  value__variance|V_10m  \\\nid                                                                   \n2018-05-01 02:00:00                0.000000               0.000000   \n2018-05-01 03:00:00                0.820564               0.003824   \n2018-05-01 04:00:00                1.045847               0.253942   \n2018-05-01 05:00:00                4.356622               0.202684   \n2018-05-01 06:00:00                4.485969               0.198239   \n\n                     value__variance_larger_than_standard_deviation|CLCT  \\\nid                                                                         \n2018-05-01 02:00:00                                                0.0     \n2018-05-01 03:00:00                                                1.0     \n2018-05-01 04:00:00                                                1.0     \n2018-05-01 05:00:00                                                1.0     \n2018-05-01 06:00:00                                                1.0     \n\n                     value__variance_larger_than_standard_deviation|T  \\\nid                                                                      \n2018-05-01 02:00:00                                               0.0   \n2018-05-01 03:00:00                                               0.0   \n2018-05-01 04:00:00                                               0.0   \n2018-05-01 05:00:00                                               0.0   \n2018-05-01 06:00:00                                               0.0   \n\n                     value__variance_larger_than_standard_deviation|U_100m  \\\nid                                                                           \n2018-05-01 02:00:00                                                0.0       \n2018-05-01 03:00:00                                                0.0       \n2018-05-01 04:00:00                                                0.0       \n2018-05-01 05:00:00                                                1.0       \n2018-05-01 06:00:00                                                1.0       \n\n                     value__variance_larger_than_standard_deviation|U_10m  \\\nid                                                                          \n2018-05-01 02:00:00                                                0.0      \n2018-05-01 03:00:00                                                0.0      \n2018-05-01 04:00:00                                                0.0      \n2018-05-01 05:00:00                                                0.0      \n2018-05-01 06:00:00                                                0.0      \n\n                     value__variance_larger_than_standard_deviation|V_100m  \\\nid                                                                           \n2018-05-01 02:00:00                                                0.0       \n2018-05-01 03:00:00                                                0.0       \n2018-05-01 04:00:00                                                1.0       \n2018-05-01 05:00:00                                                1.0       \n2018-05-01 06:00:00                                                1.0       \n\n                     value__variance_larger_than_standard_deviation|V_10m  \nid                                                                         \n2018-05-01 02:00:00                                                0.0     \n2018-05-01 03:00:00                                                0.0     \n2018-05-01 04:00:00                                                0.0     \n2018-05-01 05:00:00                                                0.0     \n2018-05-01 06:00:00                                                0.0     \n\n[5 rows x 4536 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value__abs_energy|CLCT</th>\n      <th>value__abs_energy|T</th>\n      <th>value__abs_energy|U_100m</th>\n      <th>value__abs_energy|U_10m</th>\n      <th>value__abs_energy|V_100m</th>\n      <th>value__abs_energy|V_10m</th>\n      <th>value__absolute_sum_of_changes|CLCT</th>\n      <th>value__absolute_sum_of_changes|T</th>\n      <th>value__absolute_sum_of_changes|U_100m</th>\n      <th>value__absolute_sum_of_changes|U_10m</th>\n      <th>...</th>\n      <th>value__variance|U_100m</th>\n      <th>value__variance|U_10m</th>\n      <th>value__variance|V_100m</th>\n      <th>value__variance|V_10m</th>\n      <th>value__variance_larger_than_standard_deviation|CLCT</th>\n      <th>value__variance_larger_than_standard_deviation|T</th>\n      <th>value__variance_larger_than_standard_deviation|U_100m</th>\n      <th>value__variance_larger_than_standard_deviation|U_10m</th>\n      <th>value__variance_larger_than_standard_deviation|V_100m</th>\n      <th>value__variance_larger_than_standard_deviation|V_10m</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>6813.370572</td>\n      <td>82047.8736</td>\n      <td>5.055752</td>\n      <td>1.574030</td>\n      <td>10.613261</td>\n      <td>0.083919</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>16811.539518</td>\n      <td>163992.6612</td>\n      <td>10.982542</td>\n      <td>7.778652</td>\n      <td>12.704466</td>\n      <td>0.254793</td>\n      <td>17.447701</td>\n      <td>0.18</td>\n      <td>0.186000</td>\n      <td>1.236305</td>\n      <td>...</td>\n      <td>0.008649</td>\n      <td>0.382112</td>\n      <td>0.820564</td>\n      <td>0.003824</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>26487.652359</td>\n      <td>246361.6612</td>\n      <td>13.897765</td>\n      <td>8.772845</td>\n      <td>13.433347</td>\n      <td>2.257409</td>\n      <td>19.071310</td>\n      <td>0.92</td>\n      <td>0.913098</td>\n      <td>2.730120</td>\n      <td>...</td>\n      <td>0.095117</td>\n      <td>0.425138</td>\n      <td>1.045847</td>\n      <td>0.253942</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>35486.186521</td>\n      <td>327461.3096</td>\n      <td>27.635908</td>\n      <td>9.248391</td>\n      <td>52.089410</td>\n      <td>3.181777</td>\n      <td>22.577941</td>\n      <td>3.14</td>\n      <td>6.327000</td>\n      <td>3.037614</td>\n      <td>...</td>\n      <td>6.458769</td>\n      <td>0.467797</td>\n      <td>4.356622</td>\n      <td>0.202684</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 06:00:00</th>\n      <td>44684.124127</td>\n      <td>408378.8012</td>\n      <td>42.177927</td>\n      <td>9.333069</td>\n      <td>81.733079</td>\n      <td>3.268781</td>\n      <td>23.623216</td>\n      <td>3.46</td>\n      <td>6.433900</td>\n      <td>3.436218</td>\n      <td>...</td>\n      <td>8.384555</td>\n      <td>0.556415</td>\n      <td>4.485969</td>\n      <td>0.198239</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 4536 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "tsfresh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.loc[:, tsfresh_data.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = feature_data.merge(tsfresh_data,left_on=feature_data.index,right_on=tsfresh_data.index,how='left')\n",
    "\n",
    "final_features = final_features.rename({'key_0':'Date'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_features.drop(['ID','WF','Set','Date'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = transform_data(final_features[features])\n",
    "y_train = transform_data(y_train[['Production']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = xgb.XGBRegressor(tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = LOFO_GPU_Importance(final_features,y_train['Production'],features,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.to_excel('Importance_DF_WF1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}