{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cnr_methods import get_simplified_data, transform_data\n",
    "\n",
    "# Feature Engineering Library for Time Series\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Feature Selection Libraries\n",
    "from cnr_methods import LOFO_GPU_Importance\n",
    "import xgboost as xgb\n",
    "\n",
    "#Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this pipeline, only Training Set will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_simplified_data()\n",
    "full_data = full_data[full_data['Set']=='Train']\n",
    "y_train = pd.read_csv('Data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the other Notebooks, we will transform the Column 'Time' to Datetime format and set as the index of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Time'] = pd.to_datetime(full_data['Time'],dayfirst=True)\n",
    "full_data = full_data.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     ID   WF    U_100m    V_100m     U_10m     V_10m       T  \\\nTime                                                                           \n2018-05-01 01:00:00   1  WF1 -2.248500 -3.257800  1.254603 -0.289687  286.44   \n2018-05-01 02:00:00   2  WF1 -2.434500 -1.446100  2.490908 -0.413370  286.26   \n2018-05-01 03:00:00   3  WF1 -1.707402 -0.853745  0.997093 -1.415138  287.00   \n2018-05-01 04:00:00   4  WF1  3.706500 -6.217400  0.689598 -0.961441  284.78   \n2018-05-01 05:00:00   5  WF1  3.813400 -5.444600  0.290994 -0.294963  284.46   \n\n                          CLCT    Set  \nTime                                   \n2018-05-01 01:00:00  82.543144  Train  \n2018-05-01 02:00:00  99.990844  Train  \n2018-05-01 03:00:00  98.367235  Train  \n2018-05-01 04:00:00  94.860604  Train  \n2018-05-01 05:00:00  95.905879  Train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>WF</th>\n      <th>U_100m</th>\n      <th>V_100m</th>\n      <th>U_10m</th>\n      <th>V_10m</th>\n      <th>T</th>\n      <th>CLCT</th>\n      <th>Set</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 01:00:00</th>\n      <td>1</td>\n      <td>WF1</td>\n      <td>-2.248500</td>\n      <td>-3.257800</td>\n      <td>1.254603</td>\n      <td>-0.289687</td>\n      <td>286.44</td>\n      <td>82.543144</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>2</td>\n      <td>WF1</td>\n      <td>-2.434500</td>\n      <td>-1.446100</td>\n      <td>2.490908</td>\n      <td>-0.413370</td>\n      <td>286.26</td>\n      <td>99.990844</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>3</td>\n      <td>WF1</td>\n      <td>-1.707402</td>\n      <td>-0.853745</td>\n      <td>0.997093</td>\n      <td>-1.415138</td>\n      <td>287.00</td>\n      <td>98.367235</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>4</td>\n      <td>WF1</td>\n      <td>3.706500</td>\n      <td>-6.217400</td>\n      <td>0.689598</td>\n      <td>-0.961441</td>\n      <td>284.78</td>\n      <td>94.860604</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>5</td>\n      <td>WF1</td>\n      <td>3.813400</td>\n      <td>-5.444600</td>\n      <td>0.290994</td>\n      <td>-0.294963</td>\n      <td>284.46</td>\n      <td>95.905879</td>\n      <td>Train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the work, we will generate features for just one Wind Farm. When doing modelling, the features, as the models, will be generated for all Wind Farms separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF = 'WF1'\n",
    "data = full_data[full_data['WF']==WF]\n",
    "y_train = y_train[y_train['ID'].isin(data['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                       ID   WF    U_100m    V_100m     U_10m     V_10m  \\\nTime                                                                     \n2018-05-01 01:00:00     1  WF1 -2.248500 -3.257800  1.254603 -0.289687   \n2018-05-01 02:00:00     2  WF1 -2.434500 -1.446100  2.490908 -0.413370   \n2018-05-01 03:00:00     3  WF1 -1.707402 -0.853745  0.997093 -1.415138   \n2018-05-01 04:00:00     4  WF1  3.706500 -6.217400  0.689598 -0.961441   \n2018-05-01 05:00:00     5  WF1  3.813400 -5.444600  0.290994 -0.294963   \n...                   ...  ...       ...       ...       ...       ...   \n2019-01-15 20:00:00  6235  WF1 -2.211200 -7.284650 -0.075525 -2.365039   \n2019-01-15 21:00:00  6236  WF1 -1.414258 -5.488200 -0.306579 -2.134722   \n2019-01-15 22:00:00  6237  WF1 -2.825250 -5.779000 -0.574004 -1.896251   \n2019-01-15 23:00:00  6238  WF1 -2.964050 -4.223850 -0.491896 -1.827700   \n2019-01-16 00:00:00  6239  WF1 -2.639321 -1.667974 -0.490542 -1.784979   \n\n                              T       CLCT    Set  \nTime                                               \n2018-05-01 01:00:00  286.440000  82.543144  Train  \n2018-05-01 02:00:00  286.260000  99.990844  Train  \n2018-05-01 03:00:00  287.000000  98.367235  Train  \n2018-05-01 04:00:00  284.780000  94.860604  Train  \n2018-05-01 05:00:00  284.460000  95.905879  Train  \n...                         ...        ...    ...  \n2019-01-15 20:00:00  280.085000   0.000000  Train  \n2019-01-15 21:00:00  280.312534   0.000000  Train  \n2019-01-15 22:00:00  279.285000   0.000000  Train  \n2019-01-15 23:00:00  279.055000   0.000000  Train  \n2019-01-16 00:00:00  280.364392   0.000000  Train  \n\n[6239 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>WF</th>\n      <th>U_100m</th>\n      <th>V_100m</th>\n      <th>U_10m</th>\n      <th>V_10m</th>\n      <th>T</th>\n      <th>CLCT</th>\n      <th>Set</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 01:00:00</th>\n      <td>1</td>\n      <td>WF1</td>\n      <td>-2.248500</td>\n      <td>-3.257800</td>\n      <td>1.254603</td>\n      <td>-0.289687</td>\n      <td>286.440000</td>\n      <td>82.543144</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>2</td>\n      <td>WF1</td>\n      <td>-2.434500</td>\n      <td>-1.446100</td>\n      <td>2.490908</td>\n      <td>-0.413370</td>\n      <td>286.260000</td>\n      <td>99.990844</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>3</td>\n      <td>WF1</td>\n      <td>-1.707402</td>\n      <td>-0.853745</td>\n      <td>0.997093</td>\n      <td>-1.415138</td>\n      <td>287.000000</td>\n      <td>98.367235</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>4</td>\n      <td>WF1</td>\n      <td>3.706500</td>\n      <td>-6.217400</td>\n      <td>0.689598</td>\n      <td>-0.961441</td>\n      <td>284.780000</td>\n      <td>94.860604</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>5</td>\n      <td>WF1</td>\n      <td>3.813400</td>\n      <td>-5.444600</td>\n      <td>0.290994</td>\n      <td>-0.294963</td>\n      <td>284.460000</td>\n      <td>95.905879</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 20:00:00</th>\n      <td>6235</td>\n      <td>WF1</td>\n      <td>-2.211200</td>\n      <td>-7.284650</td>\n      <td>-0.075525</td>\n      <td>-2.365039</td>\n      <td>280.085000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 21:00:00</th>\n      <td>6236</td>\n      <td>WF1</td>\n      <td>-1.414258</td>\n      <td>-5.488200</td>\n      <td>-0.306579</td>\n      <td>-2.134722</td>\n      <td>280.312534</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 22:00:00</th>\n      <td>6237</td>\n      <td>WF1</td>\n      <td>-2.825250</td>\n      <td>-5.779000</td>\n      <td>-0.574004</td>\n      <td>-1.896251</td>\n      <td>279.285000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-15 23:00:00</th>\n      <td>6238</td>\n      <td>WF1</td>\n      <td>-2.964050</td>\n      <td>-4.223850</td>\n      <td>-0.491896</td>\n      <td>-1.827700</td>\n      <td>279.055000</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2019-01-16 00:00:00</th>\n      <td>6239</td>\n      <td>WF1</td>\n      <td>-2.639321</td>\n      <td>-1.667974</td>\n      <td>-0.490542</td>\n      <td>-1.784979</td>\n      <td>280.364392</td>\n      <td>0.000000</td>\n      <td>Train</td>\n    </tr>\n  </tbody>\n</table>\n<p>6239 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, using the Zonal and Meridional Components of Wind, the Magnitude and Direction of Wind Vector for 100m and 10m height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]\n",
    "feature_data['Wind Speed 100m'] = np.sqrt(feature_data['U_100m']**2 + feature_data['V_100m']**2)\n",
    "feature_data['Wind Direction 100m'] = np.arctan(feature_data['V_100m']/feature_data['U_100m'])\n",
    "feature_data['Wind Speed 10m'] = np.sqrt(feature_data['U_10m']**2 + feature_data['V_10m']**2)\n",
    "feature_data['Wind Direction 10m'] = np.arctan(feature_data['V_10m']/feature_data['U_10m'])\n",
    "feature_data = feature_data.drop(['U_100m','V_100m','U_10m','V_10m'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Reference for Negative Angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data['Wind Direction 100m'] = feature_data['Wind Direction 100m'].apply(lambda x: 360 + x if x < 0 else x)\n",
    "feature_data['Wind Direction 10m'] = feature_data['Wind Direction 10m'].apply(lambda x: 360 + x if x < 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wind Speed and Direction instead of U and V, we will create some variables over the Numerical Variables from the simplified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['T', 'CLCT', 'Wind Speed 100m','Wind Direction 100m', 'Wind Speed 10m', 'Wind Direction 10m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Relative Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,  Values for Last Week and Month for each Numerical Feature are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_last_week'] = feature_data[column].shift(7)\n",
    "    feature_data[column + '_last_month'] = feature_data[column].shift(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Month and Quarter Statistics(Mean,Median,Variance) are generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data['Month_Number'] = feature_data.index.month\n",
    "feature_data['Quarter_Number'] = feature_data.index.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "mean_month = feature_data.groupby('Month_Number').mean()[features]\n",
    "median_month = feature_data.groupby('Month_Number').median()[features]\n",
    "variance_month = feature_data.groupby('Month_Number').var()[features]\n",
    "\n",
    "# Quarter\n",
    "mean_quarter = feature_data.groupby('Quarter_Number').mean()[features]\n",
    "median_quarter = feature_data.groupby('Quarter_Number').median()[features]\n",
    "variance_quarter = feature_data.groupby('Quarter_Number').var()[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "mean_month.columns = mean_month.columns + '_Month_Mean'\n",
    "median_month.columns = median_month.columns + '_Month_Median'\n",
    "variance_month.columns = variance_month.columns + '_Month_Variance'\n",
    "\n",
    "# Quarter\n",
    "mean_quarter.columns = mean_quarter.columns + '_Quarter_Mean'\n",
    "median_quarter.columns = median_quarter.columns + '_Quarterh_Median'\n",
    "variance_quarter.columns = variance_quarter.columns + '_Quarter_Variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month\n",
    "feature_data = feature_data.merge(mean_month,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(median_month,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(variance_month,on='Month_Number',how='left')\n",
    "\n",
    "# Quarter\n",
    "feature_data = feature_data.merge(mean_quarter,on='Quarter_Number',how='left')\n",
    "feature_data = feature_data.merge(median_quarter,on='Quarter_Number',how='left')\n",
    "feature_data = feature_data.merge(variance_quarter,on='Quarter_Number',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.index = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For periodical Features, here represented by days (Of Month, Week and Year), hour and minutes, the features are applied to sinusoidal functions to replicate the cyclic nature of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = feature_data.index.day\n",
    "hour = feature_data.index.hour\n",
    "minute = feature_data.index.minute\n",
    "dayofweek = feature_data.index.dayofweek\n",
    "dayofyear = feature_data.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_in_month = feature_data.index.days_in_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data[\"cos_day\"], feature_data[\"sin_day\"] = (\n",
    "    np.cos(2 * np.pi * (day - 1) / days_in_month),\n",
    "    np.sin(2 * np.pi * (day - 1) / days_in_month),\n",
    "    )\n",
    "\n",
    "feature_data[\"cos_hour\"], feature_data[\"sin_hour\"] = (\n",
    "    np.cos(2 * np.pi * hour / 24),\n",
    "    np.sin(2 * np.pi * hour / 24),\n",
    "    )\n",
    "\n",
    "feature_data[\"cos_minute\"], feature_data[\"sin_minute\"] = (\n",
    "    np.cos(2 * np.pi * minute / 60),\n",
    "    np.sin(2 * np.pi * minute / 60),\n",
    ")\n",
    "\n",
    "feature_data[\"cos_dayofyear\"], feature_data[\"sin_dayofyear\"] = (\n",
    "    np.cos(2 * np.pi * (dayofyear - 1) / 365),\n",
    "    np.sin(2 * np.pi * (dayofyear - 1) / 365),\n",
    ")\n",
    "\n",
    "feature_data[\"cos_dayofweek\"], feature_data[\"sin_dayofweek\"] = (\n",
    "    np.cos(2 * np.pi * dayofweek / 7),\n",
    "    np.sin(2 * np.pi * dayofweek / 7),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance of Position of Max and Min (Already on Tsfresh, check it later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_Distance_Max'] = feature_data.index - feature_data[column].idxmax()\n",
    "    feature_data[column + '_Distance_Min'] = feature_data.index - feature_data[column].idxmin()\n",
    "    feature_data[column + '_Distance_Max'] = feature_data[column + '_Distance_Max'].apply(lambda x : x.days)\n",
    "    feature_data[column + '_Distance_Min'] = feature_data[column + '_Distance_Min'].apply(lambda x : x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Tsfresh, a Python Library that automates Feature Engineering for Time Series Data. We generate new features for all the columns on the Simplified Data, as done below.\n",
    "\n",
    "A list of the generated features can be found https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Feature Extraction: 100%|██████████| 15/15 [02:20<00:00,  9.38s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:15<00:00,  9.06s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:17<00:00,  9.17s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:23<00:00,  9.60s/it]\nFeature Extraction: 100%|██████████| 15/15 [02:24<00:00,  9.61s/it]\nFeature Extraction: 100%|██████████| 15/15 [01:55<00:00,  7.69s/it]\n"
    }
   ],
   "source": [
    "tsfresh_data = pd.DataFrame()\n",
    "for variable in ['U_100m','V_100m','U_10m','V_10m','T','CLCT']: \n",
    "    df_shift, y = make_forecasting_frame(data[variable],kind=variable,max_timeshift=20,rolling_direction=1)\n",
    "    X = extract_features(df_shift, column_id=\"id\", column_sort=\"time\", column_value=\"value\", impute_function=impute,show_warnings=False,n_jobs=3)\n",
    "    X['Feature'] = variable\n",
    "    tsfresh_data = tsfresh_data.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a little preprocess is done to convert the generated features to the appropriate tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.pivot(columns='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data.columns = tsfresh_data.columns.map('{0[0]}|{0[1]}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant Columns are removed from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.loc[:, tsfresh_data.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     value__abs_energy|CLCT  value__abs_energy|T  \\\nid                                                                 \n2018-05-01 02:00:00             6813.370572           82047.8736   \n2018-05-01 03:00:00            16811.539518          163992.6612   \n2018-05-01 04:00:00            26487.652359          246361.6612   \n2018-05-01 05:00:00            35486.186521          327461.3096   \n2018-05-01 06:00:00            44684.124127          408378.8012   \n\n                     value__abs_energy|U_100m  value__abs_energy|U_10m  \\\nid                                                                       \n2018-05-01 02:00:00                  5.055752                 1.574030   \n2018-05-01 03:00:00                 10.982542                 7.778652   \n2018-05-01 04:00:00                 13.897765                 8.772845   \n2018-05-01 05:00:00                 27.635908                 9.248391   \n2018-05-01 06:00:00                 42.177927                 9.333069   \n\n                     value__abs_energy|V_100m  value__abs_energy|V_10m  \\\nid                                                                       \n2018-05-01 02:00:00                 10.613261                 0.083919   \n2018-05-01 03:00:00                 12.704466                 0.254793   \n2018-05-01 04:00:00                 13.433347                 2.257409   \n2018-05-01 05:00:00                 52.089410                 3.181777   \n2018-05-01 06:00:00                 81.733079                 3.268781   \n\n                     value__absolute_sum_of_changes|CLCT  \\\nid                                                         \n2018-05-01 02:00:00                             0.000000   \n2018-05-01 03:00:00                            17.447701   \n2018-05-01 04:00:00                            19.071310   \n2018-05-01 05:00:00                            22.577941   \n2018-05-01 06:00:00                            23.623216   \n\n                     value__absolute_sum_of_changes|T  \\\nid                                                      \n2018-05-01 02:00:00                              0.00   \n2018-05-01 03:00:00                              0.18   \n2018-05-01 04:00:00                              0.92   \n2018-05-01 05:00:00                              3.14   \n2018-05-01 06:00:00                              3.46   \n\n                     value__absolute_sum_of_changes|U_100m  \\\nid                                                           \n2018-05-01 02:00:00                               0.000000   \n2018-05-01 03:00:00                               0.186000   \n2018-05-01 04:00:00                               0.913098   \n2018-05-01 05:00:00                               6.327000   \n2018-05-01 06:00:00                               6.433900   \n\n                     value__absolute_sum_of_changes|U_10m  ...  \\\nid                                                         ...   \n2018-05-01 02:00:00                              0.000000  ...   \n2018-05-01 03:00:00                              1.236305  ...   \n2018-05-01 04:00:00                              2.730120  ...   \n2018-05-01 05:00:00                              3.037614  ...   \n2018-05-01 06:00:00                              3.436218  ...   \n\n                     value__variance|U_100m  value__variance|U_10m  \\\nid                                                                   \n2018-05-01 02:00:00                0.000000               0.000000   \n2018-05-01 03:00:00                0.008649               0.382112   \n2018-05-01 04:00:00                0.095117               0.425138   \n2018-05-01 05:00:00                6.458769               0.467797   \n2018-05-01 06:00:00                8.384555               0.556415   \n\n                     value__variance|V_100m  value__variance|V_10m  \\\nid                                                                   \n2018-05-01 02:00:00                0.000000               0.000000   \n2018-05-01 03:00:00                0.820564               0.003824   \n2018-05-01 04:00:00                1.045847               0.253942   \n2018-05-01 05:00:00                4.356622               0.202684   \n2018-05-01 06:00:00                4.485969               0.198239   \n\n                     value__variance_larger_than_standard_deviation|CLCT  \\\nid                                                                         \n2018-05-01 02:00:00                                                0.0     \n2018-05-01 03:00:00                                                1.0     \n2018-05-01 04:00:00                                                1.0     \n2018-05-01 05:00:00                                                1.0     \n2018-05-01 06:00:00                                                1.0     \n\n                     value__variance_larger_than_standard_deviation|T  \\\nid                                                                      \n2018-05-01 02:00:00                                               0.0   \n2018-05-01 03:00:00                                               0.0   \n2018-05-01 04:00:00                                               0.0   \n2018-05-01 05:00:00                                               0.0   \n2018-05-01 06:00:00                                               0.0   \n\n                     value__variance_larger_than_standard_deviation|U_100m  \\\nid                                                                           \n2018-05-01 02:00:00                                                0.0       \n2018-05-01 03:00:00                                                0.0       \n2018-05-01 04:00:00                                                0.0       \n2018-05-01 05:00:00                                                1.0       \n2018-05-01 06:00:00                                                1.0       \n\n                     value__variance_larger_than_standard_deviation|U_10m  \\\nid                                                                          \n2018-05-01 02:00:00                                                0.0      \n2018-05-01 03:00:00                                                0.0      \n2018-05-01 04:00:00                                                0.0      \n2018-05-01 05:00:00                                                0.0      \n2018-05-01 06:00:00                                                0.0      \n\n                     value__variance_larger_than_standard_deviation|V_100m  \\\nid                                                                           \n2018-05-01 02:00:00                                                0.0       \n2018-05-01 03:00:00                                                0.0       \n2018-05-01 04:00:00                                                1.0       \n2018-05-01 05:00:00                                                1.0       \n2018-05-01 06:00:00                                                1.0       \n\n                     value__variance_larger_than_standard_deviation|V_10m  \nid                                                                         \n2018-05-01 02:00:00                                                0.0     \n2018-05-01 03:00:00                                                0.0     \n2018-05-01 04:00:00                                                0.0     \n2018-05-01 05:00:00                                                0.0     \n2018-05-01 06:00:00                                                0.0     \n\n[5 rows x 2118 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value__abs_energy|CLCT</th>\n      <th>value__abs_energy|T</th>\n      <th>value__abs_energy|U_100m</th>\n      <th>value__abs_energy|U_10m</th>\n      <th>value__abs_energy|V_100m</th>\n      <th>value__abs_energy|V_10m</th>\n      <th>value__absolute_sum_of_changes|CLCT</th>\n      <th>value__absolute_sum_of_changes|T</th>\n      <th>value__absolute_sum_of_changes|U_100m</th>\n      <th>value__absolute_sum_of_changes|U_10m</th>\n      <th>...</th>\n      <th>value__variance|U_100m</th>\n      <th>value__variance|U_10m</th>\n      <th>value__variance|V_100m</th>\n      <th>value__variance|V_10m</th>\n      <th>value__variance_larger_than_standard_deviation|CLCT</th>\n      <th>value__variance_larger_than_standard_deviation|T</th>\n      <th>value__variance_larger_than_standard_deviation|U_100m</th>\n      <th>value__variance_larger_than_standard_deviation|U_10m</th>\n      <th>value__variance_larger_than_standard_deviation|V_100m</th>\n      <th>value__variance_larger_than_standard_deviation|V_10m</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-01 02:00:00</th>\n      <td>6813.370572</td>\n      <td>82047.8736</td>\n      <td>5.055752</td>\n      <td>1.574030</td>\n      <td>10.613261</td>\n      <td>0.083919</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 03:00:00</th>\n      <td>16811.539518</td>\n      <td>163992.6612</td>\n      <td>10.982542</td>\n      <td>7.778652</td>\n      <td>12.704466</td>\n      <td>0.254793</td>\n      <td>17.447701</td>\n      <td>0.18</td>\n      <td>0.186000</td>\n      <td>1.236305</td>\n      <td>...</td>\n      <td>0.008649</td>\n      <td>0.382112</td>\n      <td>0.820564</td>\n      <td>0.003824</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 04:00:00</th>\n      <td>26487.652359</td>\n      <td>246361.6612</td>\n      <td>13.897765</td>\n      <td>8.772845</td>\n      <td>13.433347</td>\n      <td>2.257409</td>\n      <td>19.071310</td>\n      <td>0.92</td>\n      <td>0.913098</td>\n      <td>2.730120</td>\n      <td>...</td>\n      <td>0.095117</td>\n      <td>0.425138</td>\n      <td>1.045847</td>\n      <td>0.253942</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 05:00:00</th>\n      <td>35486.186521</td>\n      <td>327461.3096</td>\n      <td>27.635908</td>\n      <td>9.248391</td>\n      <td>52.089410</td>\n      <td>3.181777</td>\n      <td>22.577941</td>\n      <td>3.14</td>\n      <td>6.327000</td>\n      <td>3.037614</td>\n      <td>...</td>\n      <td>6.458769</td>\n      <td>0.467797</td>\n      <td>4.356622</td>\n      <td>0.202684</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-01 06:00:00</th>\n      <td>44684.124127</td>\n      <td>408378.8012</td>\n      <td>42.177927</td>\n      <td>9.333069</td>\n      <td>81.733079</td>\n      <td>3.268781</td>\n      <td>23.623216</td>\n      <td>3.46</td>\n      <td>6.433900</td>\n      <td>3.436218</td>\n      <td>...</td>\n      <td>8.384555</td>\n      <td>0.556415</td>\n      <td>4.485969</td>\n      <td>0.198239</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2118 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tsfresh_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all the Features Generated have to be filtered, so only the most relevant ones are passed to the model, as a way of avoiding Overfitting. For this process, a process called LOFO (Leave One Feature Out) is selected.\n",
    "\n",
    "The process is simple: For each Feature, a arbitrary Model (Here a XGBoost) is cross validated on a dataset that contains all the features except one, which importance is being measured, and the precision without that feature is compared to a baseline, where all features are present. The features whose removal leads to worse results are considered most important features to the dataset.\n",
    "\n",
    "More info about this process can be found on https://github.com/aerdem4/lofo-importance.\n",
    "\n",
    "The implementation of this method on this however, was an adaptation of the original code to allow use of GPU resources as a faster way to obtain results, since this work involves a big number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = feature_data.merge(tsfresh_data,left_on=feature_data.index,right_on=tsfresh_data.index,how='left')\n",
    "\n",
    "final_features = final_features.rename({'key_0':'Date'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_features.drop(['ID','WF','Set','Date'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = transform_data(final_features[features])\n",
    "y_train = transform_data(y_train[['Production']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = xgb.XGBRegressor(tree_method='gpu_hist',objective='reg:squarederror',eval_metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1/2196 8.235510 s/it\n2/2196 8.221857 s/it\n3/2196 8.73658 s/it\n4/2196 8.288028 s/it\n5/2196 8.106969 s/it\n6/2196 8.204000 s/it\n7/2196 8.348807 s/it\n8/2196 8.204999 s/it\n9/2196 8.220614 s/it\n10/2196 8.444154 s/it\n11/2196 8.417513 s/it\n12/2196 8.245509 s/it\n13/2196 8.320002 s/it\n14/2196 8.206507 s/it\n15/2196 8.270022 s/it\n16/2196 8.250000 s/it\n17/2196 8.250031 s/it\n18/2196 8.270552 s/it\n19/2196 8.319711 s/it\n20/2196 8.263542 s/it\n21/2196 8.257689 s/it\n22/2196 8.306017 s/it\n23/2196 8.296001 s/it\n24/2196 8.265662 s/it\n25/2196 8.349069 s/it\n26/2196 8.297812 s/it\n27/2196 8.268560 s/it\n28/2196 8.314512 s/it\n29/2196 8.351964 s/it\n30/2196 8.337581 s/it\n31/2196 8.940017 s/it\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b9250ea8a1d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimportance_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLOFO_GPU_Importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Production'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\andre_\\OneDrive\\Documentos\\GitHub\\cnr\\cnr_methods.py\u001b[0m in \u001b[0;36mLOFO_GPU_Importance\u001b[1;34m(X, y, features, model)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mfeature_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlofo_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfeature_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre_\\OneDrive\\Documentos\\GitHub\\cnr\\cnr_methods.py\u001b[0m in \u001b[0;36mlofo_score\u001b[1;34m(X, y, features, feature_out, model)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlofo_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mfeature_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlofo_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mmodel_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mlofo_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre_\\OneDrive\\Documentos\\GitHub\\cnr\\cnr_methods.py\u001b[0m in \u001b[0;36mlofo_df\u001b[1;34m(df, y, features, feature_out)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_out\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mgpu_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfeature_out\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mgpu_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgpu_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cupy\\creation\\from_data.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importance_df = LOFO_GPU_Importance(final_features,y_train['Production'],features,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.to_excel('Importance_DF_WF1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}