{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective fo this notebook is to utilize some methods to find and determine the optimal model to solve the challenge problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "from cnr_methods import get_simplified_data, transform_data, metric_cnr\n",
    "import tsfresh\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from collections import deque\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the data used correspond to the results of the Feature Engineering and Selection Step. (Add Later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially using the Original Data\n",
    "full_data = get_simplified_data()\n",
    "full_data['Time'] = pd.to_datetime(full_data['Time'],dayfirst=True)\n",
    "full_data = full_data.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_data[full_data['Set']=='Train']\n",
    "y = pd.read_csv('Data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial debugging, only One Windfarm will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF = 'WF1'\n",
    "X = X[X['WF']==WF]\n",
    "y = y[y['ID'].isin(X['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_features = []\n",
    "manual_features = []\n",
    "for feature in selected_features:\n",
    "    if feature.__contains__('|'):\n",
    "        tsfresh_features.append(feature)\n",
    "    else:\n",
    "        manual_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_features = [x.split('|')[0] for x in tsfresh_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'value': {'energy_ratio_by_chunks': [{'num_segments': 10, 'segment_focus': 9},\n   {'num_segments': 10, 'segment_focus': 9},\n   {'num_segments': 10, 'segment_focus': 9}],\n  'friedrich_coefficients': [{'m': 3, 'r': 30, 'coeff': 2}],\n  'time_reversal_asymmetry_statistic': [{'lag': 3}, {'lag': 1}],\n  'c3': [{'lag': 2}, {'lag': 3}],\n  'cid_ce': [{'normalize': False}],\n  'quantile': [{'q': 0.1}, {'q': 0.9}, {'q': 0.1}, {'q': 0.3}],\n  'cwt_coefficients': [{'widths': (2, 5, 10, 20), 'coeff': 3, 'w': 5},\n   {'widths': (2, 5, 10, 20), 'coeff': 11, 'w': 5},\n   {'widths': (2, 5, 10, 20), 'coeff': 9, 'w': 20},\n   {'widths': (2, 5, 10, 20), 'coeff': 11, 'w': 2},\n   {'widths': (2, 5, 10, 20), 'coeff': 11, 'w': 5},\n   {'widths': (2, 5, 10, 20), 'coeff': 0, 'w': 2},\n   {'widths': (2, 5, 10, 20), 'coeff': 9, 'w': 20},\n   {'widths': (2, 5, 10, 20), 'coeff': 2, 'w': 10},\n   {'widths': (2, 5, 10, 20), 'coeff': 11, 'w': 2}],\n  'change_quantiles': [{'f_agg': 'mean', 'isabs': False, 'qh': 1.0, 'ql': 0.4},\n   {'f_agg': 'mean', 'isabs': False, 'qh': 0.2, 'ql': 0.0},\n   {'f_agg': 'mean', 'isabs': False, 'qh': 1.0, 'ql': 0.8},\n   {'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.6},\n   {'f_agg': 'var', 'isabs': False, 'qh': 0.6, 'ql': 0.0},\n   {'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.6},\n   {'f_agg': 'mean', 'isabs': False, 'qh': 0.2, 'ql': 0.0},\n   {'f_agg': 'mean', 'isabs': True, 'qh': 1.0, 'ql': 0.2}],\n  'fft_coefficient': [{'coeff': 9, 'attr': 'real'},\n   {'coeff': 4, 'attr': 'angle'},\n   {'coeff': 7, 'attr': 'real'},\n   {'coeff': 2, 'attr': 'abs'},\n   {'coeff': 7, 'attr': 'imag'},\n   {'coeff': 1, 'attr': 'angle'},\n   {'coeff': 5, 'attr': 'angle'},\n   {'coeff': 8, 'attr': 'imag'}],\n  'standard_deviation': None,\n  'spkt_welch_density': [{'coeff': 8}],\n  'partial_autocorrelation': [{'lag': 4}, {'lag': 5}],\n  'minimum': None,\n  'agg_autocorrelation': [{'f_agg': 'var', 'maxlag': 40}],\n  'agg_linear_trend': [{'f_agg': 'var', 'chunk_len': 10, 'attr': 'slope'},\n   {'f_agg': 'mean', 'chunk_len': 5, 'attr': 'slope'}],\n  'linear_trend': [{'attr': 'stderr'}]}}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tsfresh.feature_extraction.settings.from_columns(tsfresh_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to the Hyperparameter search, it is necessary first to have some way to reliably measure the performance of the model. For this purpose, it will be used a Time Split Cross Validation Method, were the \"Test\" Fold for each Iteration is going to be used as the Validation Data, and so, to make Early Stopping on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_splits = 8\n",
    "num_boost_round = 100\n",
    "early_stopping_rounds = 10\n",
    "numerical_features = X.drop(['ID','WF','Set'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_df(df,y,numerical_features):\n",
    "    gpu_matrix = cp.asarray(df[[feature for feature in numerical_features]])\n",
    "    gpu_matrix = xgb.DMatrix(gpu_matrix,label=y)\n",
    "    return gpu_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(param,numerical_features=numerical_features,k_fold_splits=k_fold_splits,num_boost_round=num_boost_round,early_stopping_rounds=early_stopping_rounds):\n",
    "    # Define Time Split Cross Validation\n",
    "    tscv = TimeSeriesSplit(n_splits=k_fold_splits)\n",
    "\n",
    "    # Separating a Holdout Set\n",
    "    X_holdout = X[-round(len(X)/8):]\n",
    "    y_holdout = y[-round(len(X)/8):]\n",
    "    dhold = gpu_df(X_holdout,y_holdout['Production'],numerical_features)\n",
    "\n",
    "    X_cv = X[:-round(len(X)/8)]\n",
    "    y_cv = y[:-round(len(X)/8)]\n",
    "\n",
    "    # Set XGBoost for GPU\n",
    "    param['tree_method'] = 'gpu_hist'\n",
    "    \n",
    "    first_time = True\n",
    "    for train_index, val_index in tscv.split(X_cv):\n",
    "        # Get the Data of the Split\n",
    "        X_train, X_val = X_cv.iloc[train_index], X_cv.iloc[val_index]\n",
    "        y_train, y_val = y_cv.iloc[train_index], y_cv.iloc[val_index]\n",
    "        dtrain = gpu_df(X_train,y_train['Production'],numerical_features)\n",
    "        dval = gpu_df(X_val,y_val['Production'],numerical_features)\n",
    "\n",
    "        # Train the Model\n",
    "        watchlist = [(dtrain,'train'),(dval,'eval')]\n",
    "        if first_time == True:\n",
    "            bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=watchlist, feval=metric_cnr,early_stopping_rounds=early_stopping_rounds,verbose_eval=False)\n",
    "            first_time = False\n",
    "        else:\n",
    "            bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=watchlist, feval=metric_cnr,early_stopping_rounds=early_stopping_rounds,verbose_eval=False,xgb_model=bst)\n",
    "        \n",
    "    preds = bst.predict(dhold,ntree_limit=bst.best_ntree_limit)\n",
    "    score = metric_cnr(preds,dhold)\n",
    "    return {'loss' : score[1], 'params' : param, 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Hyperparameter Tuning, the HyperOpt Library will be used, which implements some techniques for a more efficient search for parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth' : hp.randint('max_depth', 15),\n",
    "    'subsample' : hp.uniform('subsample', 0, 1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0, 1),\n",
    "    'colsample_bylevel' : hp.uniform('colsample_bylevel', 0, 1),\n",
    "    'min_child_weight' : hp.uniform('min_child_weight', 0, 10),\n",
    "    'lambda' : hp.uniform('lambda', 0, 1),\n",
    "    'alpha' : hp.uniform('alpha', 0, 1),\n",
    "    'eta' : hp.uniform('eta', 0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algorithm = tpe.suggest\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100%|██████████| 10/10 [00:43<00:00,  4.34s/trial, best loss: 41.09568128893979]\n"
    }
   ],
   "source": [
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_data[full_data['Set']=='Train']\n",
    "X_test = full_data[full_data['Set']=='Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop of Wind Farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}