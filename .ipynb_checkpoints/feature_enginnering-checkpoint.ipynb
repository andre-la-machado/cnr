{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cnr_methods import get_simplified_data \n",
    "\n",
    "# Feature Engineering Library for Time Series\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Feature Selection Library\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this pipeline, only Training Set will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_simplified_data()\n",
    "full_data = full_data[full_data['Set']=='Train']\n",
    "y_train = pd.read_csv('Y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the other Notebooks, we will transform the Column 'Time' to Datetime format and set as the index of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Time'] = pd.to_datetime(full_data['Time'],dayfirst=True)\n",
    "full_data = full_data.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WF</th>\n",
       "      <th>U_100m</th>\n",
       "      <th>V_100m</th>\n",
       "      <th>U_10m</th>\n",
       "      <th>V_10m</th>\n",
       "      <th>T</th>\n",
       "      <th>CLCT</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>WF1</td>\n",
       "      <td>-2.248500</td>\n",
       "      <td>-3.257800</td>\n",
       "      <td>1.254603</td>\n",
       "      <td>-0.289687</td>\n",
       "      <td>286.440</td>\n",
       "      <td>82.543144</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>WF1</td>\n",
       "      <td>-2.434500</td>\n",
       "      <td>-1.446100</td>\n",
       "      <td>2.490908</td>\n",
       "      <td>-0.413370</td>\n",
       "      <td>286.260</td>\n",
       "      <td>99.990844</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>WF1</td>\n",
       "      <td>-1.220571</td>\n",
       "      <td>-0.266871</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>-1.415138</td>\n",
       "      <td>286.575</td>\n",
       "      <td>98.367235</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>WF1</td>\n",
       "      <td>3.706500</td>\n",
       "      <td>-6.217400</td>\n",
       "      <td>0.689598</td>\n",
       "      <td>-0.961441</td>\n",
       "      <td>284.780</td>\n",
       "      <td>94.860604</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01 05:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>WF1</td>\n",
       "      <td>3.813400</td>\n",
       "      <td>-5.444600</td>\n",
       "      <td>0.290994</td>\n",
       "      <td>-0.294963</td>\n",
       "      <td>284.460</td>\n",
       "      <td>95.905879</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID   WF    U_100m    V_100m     U_10m     V_10m        T  \\\n",
       "Time                                                                            \n",
       "2018-05-01 01:00:00   1  WF1 -2.248500 -3.257800  1.254603 -0.289687  286.440   \n",
       "2018-05-01 02:00:00   2  WF1 -2.434500 -1.446100  2.490908 -0.413370  286.260   \n",
       "2018-05-01 03:00:00   3  WF1 -1.220571 -0.266871  0.997093 -1.415138  286.575   \n",
       "2018-05-01 04:00:00   4  WF1  3.706500 -6.217400  0.689598 -0.961441  284.780   \n",
       "2018-05-01 05:00:00   5  WF1  3.813400 -5.444600  0.290994 -0.294963  284.460   \n",
       "\n",
       "                          CLCT    Set  \n",
       "Time                                   \n",
       "2018-05-01 01:00:00  82.543144  Train  \n",
       "2018-05-01 02:00:00  99.990844  Train  \n",
       "2018-05-01 03:00:00  98.367235  Train  \n",
       "2018-05-01 04:00:00  94.860604  Train  \n",
       "2018-05-01 05:00:00  95.905879  Train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the work, we will generate features for just one Wind Farm. When doing modelling, the features, as the models, will be generated for all Wind Farms separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF = 'WF1'\n",
    "data = full_data[full_data['WF']==WF]\n",
    "y_train = y_train[y_train['ID'].isin(data['ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]\n",
    "feature_data['Wind Speed 100m'] = np.sqrt(feature_data['U_100m']**2 + feature_data['V_100m']**2)\n",
    "feature_data['Wind Direction 100m'] = np.arctan(feature_data['V_100m']/feature_data['U_100m'])\n",
    "feature_data['Wind Speed 10m'] = np.sqrt(feature_data['U_10m']**2 + feature_data['V_10m']**2)\n",
    "feature_data['Wind Direction 10m'] = np.arctan(feature_data['V_10m']/feature_data['U_10m'])\n",
    "feature_data = feature_data.drop(['U_100m','V_100m','U_10m','V_10m'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Reference for Negative Angle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "feature_data[feature_data['Wind Direction 100m'] < 0]['Wind Direction 100m'] = 360 - feature_data[feature_data['Wind Direction 100m'] < 0]['Wind Direction 100m']\n",
    "feature_data[feature_data['Wind Direction 10m'] < 0]['Wind Direction 10m'] = 360 - feature_data[feature_data['Wind Direction 10m'] < 0]['Wind Direction 10m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wind Speed and Direction instead of U and V, we will create some variables over the Numerical Variables from the simplified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['T', 'CLCT', 'Wind Speed 100m','Wind Direction 100m', 'Wind Speed 10m', 'Wind Direction 10m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Relative Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get Values for Last Week and Month for each Numerical Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_last_week'] = feature_data[column].shift(7)\n",
    "    feature_data[column + '_last_month'] = feature_data[column].shift(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Number of Month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data['Month_Number'] = feature_data.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Month Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = feature_data.groupby('Month_Number').mean()[features]\n",
    "median = feature_data.groupby('Month_Number').median()[features]\n",
    "variance = feature_data.groupby('Month_Number').var()[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.columns = mean.columns + '_Month_Mean'\n",
    "median.columns = median.columns + '_Month_Median'\n",
    "variance.columns = variance.columns + '_Month_Variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = feature_data.merge(mean,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(median,on='Month_Number',how='left')\n",
    "feature_data = feature_data.merge(variance,on='Month_Number',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.index = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance from Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance of Position of Max and Min (Already on Tsfresh, check it later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features:\n",
    "    feature_data[column + '_Distance_Max'] = feature_data.index - feature_data[column].idxmax()\n",
    "    feature_data[column + '_Distance_Min'] = feature_data.index - feature_data[column].idxmin()\n",
    "    feature_data[column + '_Distance_Max'] = feature_data[column + '_Distance_Max'].apply(lambda x : x.days)\n",
    "    feature_data[column + '_Distance_Min'] = feature_data[column + '_Distance_Min'].apply(lambda x : x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Window Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transformations (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = feature_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Tsfresh, a Python Library that automates Feature Engineering for Time Series Data. We generate new features for all the columns on the Simplified Data, as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['ID','WF','U_100m','V_100m','U_10m','V_10m','T','CLCT','Set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:460: UserWarning: Your time stamps are not uniformly sampled, which makes rolling nonsensical in some domains.\n",
      "  warnings.warn(\"Your time stamps are not uniformly sampled, which makes rolling \"\n",
      "\n",
      "Feature Extraction:   0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\andre_\\anaconda3\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 39, in _function_with_partly_reduce\n    results = list(itertools.chain.from_iterable(results))\n  File \"C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 38, in <genexpr>\n    results = (map_function(chunk, **kwargs) for chunk in chunk_list)\n  File \"C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 390, in _do_extraction_on_chunk\n    return list(_f())\n  File \"C:\\Users\\andre_\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 355, in _f\n    func = getattr(feature_calculators, function_name)\nTypeError: getattr(): attribute name must be string\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-66b7ed9ab646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'U_100m'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'V_100m'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'U_10m'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'V_10m'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'T'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CLCT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf_shift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_forecasting_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_timeshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrolling_direction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_shift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kind'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Feature'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtsfresh_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsfresh_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor)\u001b[0m\n\u001b[0;32m    158\u001b[0m                                 \u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                                 \u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                                 distributor=distributor)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# Impute the result if requested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36m_do_extraction\u001b[1;34m(df, column_id, column_value, column_kind, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor)\u001b[0m\n\u001b[0;32m    309\u001b[0m     result = distributor.map_reduce(_do_extraction_on_chunk, data=data_in_chunks,\n\u001b[0;32m    310\u001b[0m                                     \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                     function_kwargs=kwargs)\n\u001b[0m\u001b[0;32m    312\u001b[0m     \u001b[0mdistributor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tsfresh\\utilities\\distribution.py\u001b[0m in \u001b[0;36mmap_reduce\u001b[1;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_function_with_partly_reduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "tsfresh_data = pd.DataFrame()\n",
    "for variable in ['U_100m','V_100m','U_10m','V_10m','T','CLCT']: \n",
    "    df_shift, y = make_forecasting_frame(data[variable],kind=variable,max_timeshift=20,rolling_direction=1)\n",
    "    X = extract_features(df_shift.drop('kind',axis=1),y,column_id=\"id\", column_sort=\"time\",show_warnings=False,n_jobs=3)\n",
    "    X['Feature'] = variable\n",
    "    tsfresh_data = tsfresh_data.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process tsfresh_data to pass column 'Features' to the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.pivot(columns='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data.columns = tsfresh_data.columns.map('{0[0]}|{0[1]}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_data = tsfresh_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_100m = []\n",
    "U_10m = []\n",
    "V_100m = []\n",
    "V_10m = []\n",
    "T = []\n",
    "CLCT = []\n",
    "\n",
    "\n",
    "for column in tsfresh_data.columns:\n",
    "    if column.__contains__('|U_100m'):\n",
    "        U_100m.append(column)\n",
    "    elif column.__contains__('|U_10m'):\n",
    "        U_10m.append(column)\n",
    "    elif column.__contains__('|V_100m'):\n",
    "        V_100m.append(column)\n",
    "    elif column.__contains__('|V_10m'):\n",
    "        V_10m.append(column)\n",
    "    elif (column.__contains__('|T')):\n",
    "        T.append(column)\n",
    "    elif (column.__contains__('|CLCT')):\n",
    "        CLCT.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_features_filtered = []\n",
    "for feature in [U_100m,U_10m,V_100m,V_10m,T,CLCT]:\n",
    "    relevance_table = calculate_relevance_table(tsfresh_data[feature],y,n_jobs=3)\n",
    "    tsfresh_features_filtered.append(relevance_table[relevance_table['relevant']==True].sort_values('p_value')['feature'].values[:10]) #Filter for Relevant Features Only and Maybe just the first 10\n",
    "tsfresh_features_filtered = np.concatenate(tsfresh_features_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfresh_features_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = pd.concat([feature_data,tsfresh_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the Feature Selection using Borutapy, a Python Implementation of the Famous R Method. For the method we use a Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,n_jobs=3, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector.fit(final_features.drop(['ID','WF','Set'],axis=1).values, y_train['Production'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = final_features.drop(['ID','WF','Set'],axis=1)[:, feat_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features.drop(['ID','WF','Set'],axis=1).columns[feat_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
